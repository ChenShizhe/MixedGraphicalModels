evaluation_bic2[iter,,j]<-c(Eva.count(B=B,P=P,Phi=Phi,Est=est,reverse=F), Eva.total(B=B,P=P,Phi=Phi,Est=est,reverse=F))
est<-combine_gen(ggraph,p=p,q=q, cd='or', cc='or',dd='or')
evaluation_or[iter,,j]<-c(Eva.count(B=B,P=P,Phi=Phi,Est=est,reverse=F), Eva.total(B=B,P=P,Phi=Phi,Est=est,reverse=F))
est<-combine_gen(ggraph,p=p,q=q, cd='and', cc='or',dd='or')
evaluation_and[iter,,j]<-c(Eva.count(B=B,P=P,Phi=Phi,Est=est,reverse=F), Eva.total(B=B,P=P,Phi=Phi,Est=est,reverse=F))
}
}
}
edge.rank<-edge_aver(edges=evaluation, count=count)
write.table(edge.rank, file=paste("./Estimates/G", iterg, "PB200_S.txt",sep=""))
edge.rank<-edge_aver(edges=evaluation_and, count=count)
write.table(edge.rank, file=paste("./Estimates/G", iterg, "PB200_AND.txt",sep=""))
edge.rank<-edge_aver(edges=evaluation_or, count=count)
write.table(edge.rank, file=paste("./Estimates/G", iterg, "PB200_OR.txt",sep=""))
edge.rank<-edge_aver(edges=evaluation_bic2, count=count)
write.table(edge.rank, file=paste("./Estimates/G", iterg, "PB200_BIC2.txt",sep=""))
print(count)
}
count
iter
est<-neighbour_PB(dat=rs,p=p,q=q,
clambda.g=lambda, ratio=1, pf=T, pw=sds,cf=F,maxit=10000)
## Also need to pick the correct level of samples
for( iterg in 1:M1){
B<-as.matrix(read.csv(file=paste("./Graph/graphPB", "40 B",iterg, ".csv",sep=""),header=F))
P<-as.matrix(read.csv(file=paste("./Graph/graphPB", "40 P",iterg, ".csv",sep=""),header=F))
Phi<-as.matrix(read.csv(file=paste("./Graph/graphPB", "40 Phi",iterg, ".csv",sep=""),header=F))
p<-dim(P)[1]
q<-dim(P)[2]
count<-0
edges_BIC<-array(0,c(M2,8,3))
evaluation_bic2<-evaluation_or<-evaluation_and<-evaluation<-replicate(total,matrix(0,M2,8))
for(iter in 1:M2){
rsA<-as.matrix(read.table(file=paste("./Data/sample40PB", iterg, "N400", iter,".txt",sep="" )))
rs<-rsA[1:size, ]
if(is.same(rs)==TRUE){
} else {
count<-count+1
sds<-as.numeric(apply(rs, 2, sd))
est_neighbour<-neighbour_PB(dat=rs,p=p,q=q,
clambda.g=lambda, ratio=1, pf=T, pw=sds,cf=F,maxit=10000)
#preparation for applying the seleciton rules
parameter_bic2<-parameter<-list(coef=1, a0=1)
parameter$coef<- rbind(cbind(B,P), cbind(t(P),Phi))
parameter$a0 <- c(rep(meanlow,p/2),rep(meanhigh,p/2))
bytype<-BIC_type(bic=est_neighbour$bic,p=p,q=q)
parameter_bic2$a0 <- est_neighbour$Intercept[1:p,bytype[1]+gap]
parameter_bic2$coef<- rbind(est_neighbour$N[1:p,,bytype[1]+gap],est_neighbour$N[p+(1:q),,bytype[2]+7])
for(j in 1:total){
ggraph<-abs(est_neighbour$N[,,j])
est<-combine_smart(estimate=ggraph,p=p,q=q,parameter=parameter)
evaluation[iter,,j]<-c(Eva.count(B=B,P=P,Phi=Phi,Est=est,reverse=F), Eva.total(B=B,P=P,Phi=Phi,Est=est,reverse=F))
est<-combine_smart(estimate=ggraph,p=p,q=q,parameter=parameter_bic2)
evaluation_bic2[iter,,j]<-c(Eva.count(B=B,P=P,Phi=Phi,Est=est,reverse=F), Eva.total(B=B,P=P,Phi=Phi,Est=est,reverse=F))
est<-combine_gen(ggraph,p=p,q=q, cd='or', cc='or',dd='or')
evaluation_or[iter,,j]<-c(Eva.count(B=B,P=P,Phi=Phi,Est=est,reverse=F), Eva.total(B=B,P=P,Phi=Phi,Est=est,reverse=F))
est<-combine_gen(ggraph,p=p,q=q, cd='and', cc='or',dd='or')
evaluation_and[iter,,j]<-c(Eva.count(B=B,P=P,Phi=Phi,Est=est,reverse=F), Eva.total(B=B,P=P,Phi=Phi,Est=est,reverse=F))
}
}
}
edge.rank<-edge_aver(edges=evaluation, count=count)
write.table(edge.rank, file=paste("./Estimates/G", iterg, "PB200_S.txt",sep=""))
edge.rank<-edge_aver(edges=evaluation_and, count=count)
write.table(edge.rank, file=paste("./Estimates/G", iterg, "PB200_AND.txt",sep=""))
edge.rank<-edge_aver(edges=evaluation_or, count=count)
write.table(edge.rank, file=paste("./Estimates/G", iterg, "PB200_OR.txt",sep=""))
edge.rank<-edge_aver(edges=evaluation_bic2, count=count)
write.table(edge.rank, file=paste("./Estimates/G", iterg, "PB200_BIC2.txt",sep=""))
print(count)
}
M<-5
# Edge estimated using the interction (AND) rule
edge_and<-process(st1="./Estimates/G", st2="PB200_AND.txt",range=(1:M) )
# Edges estimated using the union (OR) rule
edge_or<-process(st1="./Estimates//G", st2="PB200_OR.txt",range=(1:M) )
# Edges estimated using the selection rule based on true parameters
edge_S<-process(st1="./Estimates/G", st2="PB200_S.txt",range=(1:M) )
# Edges estimated using the selection rule based on consistent estimators
edge_bic2<-process(st1="./Estimates/G", st2="PB200_BIC2.txt",range=(1:M) )
source("../Sources/readplots.r")
# Edge estimated using the interction (AND) rule
edge_and<-process(st1="./Estimates/G", st2="PB200_AND.txt",range=(1:M) )
# Edges estimated using the union (OR) rule
edge_or<-process(st1="./Estimates//G", st2="PB200_OR.txt",range=(1:M) )
# Edges estimated using the selection rule based on true parameters
edge_S<-process(st1="./Estimates/G", st2="PB200_S.txt",range=(1:M) )
# Edges estimated using the selection rule based on consistent estimators
edge_bic2<-process(st1="./Estimates/G", st2="PB200_BIC2.txt",range=(1:M) )
plot(edge_S[,2]~edge_S[,6],type="l",xlim=c(0,400),ylim=c(0,40), lwd=4,
xlab="Number of total estimated edges", ylab=" ",col="gray", cex.lab=2.2,cex.axis=1.5)
lines(edge_bic2[,2]~edge_bic2[,6],lwd=4,lty="dashed")
lines(edge_and[,2]~edge_and[,6],col="#FF4040",lwd=4,lty="solid")
lines(edge_or[,2]~edge_or[,6],col="#FF404090",lwd=4,lty="dashed")
###--------------------------------------------------------------###
### Figure 3
### Last updated: Mar.13th 2014
###--------------------------------------------------------------###
### Note:
###     Estimates from GRaFo (Fellinghauer et al. 2013) are not included
###     Code for GRaFo can be found at
###     http://www.sciencedirect.com/science/article/pii/S0167947313000789
###--------------------------------------------------------------###
source("../Sources/readplots.r")
M<-5
# Edge estimated using the interction (AND) rule
edge_and<-process(st1="./Estimates/G", st2="PB200_AND.txt",range=(1:M) )
# Edges estimated using the union (OR) rule
edge_or<-process(st1="./Estimates//G", st2="PB200_OR.txt",range=(1:M) )
# Edges estimated using the selection rule based on true parameters
edge_S<-process(st1="./Estimates/G", st2="PB200_S.txt",range=(1:M) )
# Edges estimated using the selection rule based on consistent estimators
edge_bic2<-process(st1="./Estimates/G", st2="PB200_BIC2.txt",range=(1:M) )
pdf(file = paste("./plots/PB-diff.pdf",sep=""), width=8, height=6)
par(mar=c(4,3.6,4,0.3)) # Margins
plot(edge_S[,2]~edge_S[,6],type="l",xlim=c(0,400),ylim=c(0,40), lwd=4,
xlab="Number of total estimated edges", ylab=" ",col="gray", cex.lab=2.2,cex.axis=1.5)
lines(edge_bic2[,2]~edge_bic2[,6],lwd=4,lty="dashed")
lines(edge_and[,2]~edge_and[,6],col="#FF4040",lwd=4,lty="solid")
lines(edge_or[,2]~edge_or[,6],col="#FF404090",lwd=4,lty="dashed")
mtext("Number of true edges", side=2, line=2.2,cex=2.2)
mtext('Edges between Poisson and binary nodes', outer=T, line=-2.8,cex=2.3)
dev.off()
source("../Sources/MGM_Graph.r")
M1<-5 # Number of graphs
M2<-3 # Number of datasets for each graph
meanlow<- -3
meanhigh <- 0
for(iterg in 1:M1){
B<-as.matrix(read.csv(file=paste("./Graph/graphPB", "40 B",iterg, ".csv",sep=""),header=F))
P<-as.matrix(read.csv(file=paste("./Graph/graphPB", "40 P",iterg, ".csv",sep=""),header=F))
Phi<-as.matrix(read.csv(file=paste("./Graph/graphPB", "40 Phi",iterg, ".csv",sep=""),header=F))
p<-dim(P)[1]
q<-dim(P)[2]
alpha1<-c(rep(meanlow,p/2),rep(meanhigh,p/2))
for(iter in 1:M2){
set.seed(19+23*iter)
###For simulation in the paper: Gibbs.n=500, burnin=3000
rs<-sampler_poisson_binary(400, B=B, P=P, Phi=Phi,a0=alpha1, seedmultiplier=(19+23*iter),
Gibbs.n=20,burnin=200)
write.table(rs,file=paste("./Data/sample40PB",iterg, "N400", iter, ".txt",sep=""))
}
}
source("../Sources/MGM_Graph.r")
M1<-5
p<-q<-40
set.seed(12)
for(i in 1:M1){
gr<-generator(p=p,q=q, lwb=0.8,upb=1,PB=T)
B<-gr[[1]]
P<-gr[[2]]
Phi<-gr[[3]]
write.table(P,file=paste("./Graph/graphPB", "40 P", i,".csv",sep=""),row.names=F,col.names=F,sep=",")
write.table(B,file=paste("./Graph/graphPB", "40 B", i,".csv",sep=""),row.names=F,col.names=F,sep=",")
write.table(Phi,file=paste("./Graph/graphPB", "40 Phi", i,".csv",sep=""),row.names=F,col.names=F,sep=",")
}
source("../Sources/MGM_Sampler.r")
M1<-5 # Number of graphs
M2<-3 # Number of datasets for each graph
meanlow<- -3
meanhigh <- 0
for(iterg in 1:M1){
B<-as.matrix(read.csv(file=paste("./Graph/graphPB", "40 B",iterg, ".csv",sep=""),header=F))
P<-as.matrix(read.csv(file=paste("./Graph/graphPB", "40 P",iterg, ".csv",sep=""),header=F))
Phi<-as.matrix(read.csv(file=paste("./Graph/graphPB", "40 Phi",iterg, ".csv",sep=""),header=F))
p<-dim(P)[1]
q<-dim(P)[2]
alpha1<-c(rep(meanlow,p/2),rep(meanhigh,p/2))
for(iter in 1:M2){
set.seed(19+23*iter)
###For simulation in the paper: Gibbs.n=500, burnin=3000
rs<-sampler_poisson_binary(400, B=B, P=P, Phi=Phi,a0=alpha1, seedmultiplier=(19+23*iter),
Gibbs.n=20,burnin=200)
write.table(rs,file=paste("./Data/sample40PB",iterg, "N400", iter, ".txt",sep=""))
}
}
B<-as.matrix(read.csv(file=paste("./Graph/graphPB", "40 B",iterg, ".csv",sep=""),header=F))
P<-as.matrix(read.csv(file=paste("./Graph/graphPB", "40 P",iterg, ".csv",sep=""),header=F))
Phi<-as.matrix(read.csv(file=paste("./Graph/graphPB", "40 Phi",iterg, ".csv",sep=""),header=F))
p<-dim(P)[1]
q<-dim(P)[2]
alpha1<-c(rep(meanlow,p/2),rep(meanhigh,p/2))
set.seed(19+23*iter)
rs<-sampler_poisson_binary(400, B=B, P=P, Phi=Phi,a0=alpha1, seedmultiplier=(19+23*iter),
Gibbs.n=20,burnin=200)
source("../Sources/MGM_Evaluation.r")
source("../Sources/MGM_Combine.r")
source("../Sources/MGM_BIC.r")
source("../Sources/MGM_NSelect.r")
source("../Sources/MGM_NSelect.r")
gr<-list(1,2,3)
meanlow<- -3
meanhigh <- 0
total<-100
lambda<-exp(-seq(from= 6, to= -4, length.out=total))
#calculate the number we need in order to get 1/2
gap<-ceiling(log(2)/ log(lambda[2]/lambda[1])) #~7
size<-200
M1<-5
M2<-3
iterg<-1
B<-as.matrix(read.csv(file=paste("./Graph/graphPB", "40 B",iterg, ".csv",sep=""),header=F))
P<-as.matrix(read.csv(file=paste("./Graph/graphPB", "40 P",iterg, ".csv",sep=""),header=F))
Phi<-as.matrix(read.csv(file=paste("./Graph/graphPB", "40 Phi",iterg, ".csv",sep=""),header=F))
p<-dim(P)[1]
q<-dim(P)[2]
count<-0
edges_BIC<-array(0,c(M2,8,3))
evaluation_bic2<-evaluation_or<-evaluation_and<-evaluation<-replicate(total,matrix(0,M2,8))
iter<-1
sample_all<-as.matrix(read.table(file=paste("./Data/sample40PB", iterg, "N400", iter,".txt",sep="" )))
sample_limited<-sample_all[1:size, ]
count<-count+1
sds<-as.numeric(apply(sample_limited, 2, sd))
est_path<-neighbour_PB(dat=sample_limited,p=p,q=q,
clambda.g=lambda, ratio=1, pf=T, pw=sds,cf=F,maxit=10000)
est_path<-neighbour_PB(dat=sample_limited,p=p,q=q,
clambda=lambda, ratio=1, pf=T, pw=sds,maxit=10000)
source("../Sources/MGM_Sampler.r")
M1<-5 # Number of graphs
M2<-3 # Number of datasets for each graph
# Set the alpha_1 for poisson nodes
meanlow<- -3
meanhigh <- 0
for(iterg in 1:M1){
B<-as.matrix(read.csv(file=paste("./Graph/graphPB", "40 B",iterg, ".csv",sep=""),header=F))
P<-as.matrix(read.csv(file=paste("./Graph/graphPB", "40 P",iterg, ".csv",sep=""),header=F))
Phi<-as.matrix(read.csv(file=paste("./Graph/graphPB", "40 Phi",iterg, ".csv",sep=""),header=F))
p<-dim(P)[1]
q<-dim(P)[2]
alpha1<-c(rep(meanlow,p/2),rep(meanhigh,p/2))
for(iter in 1:M2){
set.seed(19+23*iter)
###For simulation in the paper: Gibbs.n=500, burnin=3000
rs<-sampler_poisson_binary(400, B=B, P=P, Phi=Phi,a0=alpha1, seedmultiplier=(19+23*iter),
Gibbs.n=20,burnin=200)
write.table(rs,file=paste("./Data/sample40PB",iterg, "N400", iter, ".txt",sep=""))
}
}
M1<-3
M2<-3
#####
## Also need to pick the correct level of samples
for( iterg in 1:M1){
B<-as.matrix(read.csv(file=paste("./Graph/graphPB", "40 B",iterg, ".csv",sep=""),header=F))
P<-as.matrix(read.csv(file=paste("./Graph/graphPB", "40 P",iterg, ".csv",sep=""),header=F))
Phi<-as.matrix(read.csv(file=paste("./Graph/graphPB", "40 Phi",iterg, ".csv",sep=""),header=F))
p<-dim(P)[1]
q<-dim(P)[2]
count<-0
edges_BIC<-array(0,c(M2,8,3))
evaluation_bic2<-evaluation_or<-evaluation_and<-evaluation<-replicate(total,matrix(0,M2,8))
for(iter in 1:M2){
sample_all<-as.matrix(read.table(file=paste("./Data/sample40PB", iterg, "N400", iter,".txt",sep="" )))
sample_limited<-sample_all[1:size, ]
if(is_same(sample_limited)==TRUE){
} else {
count<-count+1
sds<-as.numeric(apply(sample_limited, 2, sd))
est_path<-neighbour_PB(dat=sample_limited,p=p,q=q,
clambda=lambda, ratio=1, pf=T, pw=sds,maxit=10000)
#preparation for applying the seleciton rules
parameter_bic2<-parameter<-list(coef=1, a0=1)
parameter$coef<- rbind(cbind(B,P), cbind(t(P),Phi))
parameter$a0 <- c(rep(meanlow,p/2),rep(meanhigh,p/2))
bytype<-BIC_type(bic=est_path$bic,p=p,q=q)
parameter_bic2$a0 <- est_path$Intercept[1:p,bytype[1]+gap]
parameter_bic2$coef<- rbind(est_path$N[1:p,,bytype[1]+gap],est_path$N[p+(1:q),,bytype[2]+7])
for(j in 1:total){
ggraph<-abs(est_path$N[,,j])
est<-combine_select(estimate=ggraph,p=p,q=q,parameter=parameter)
evaluation[iter,,j]<-c(Eva_count(B=B,P=P,Phi=Phi,Est=est,reverse=F), Eva_total(B=B,P=P,Phi=Phi,Est=est,reverse=F))
est<-combine_select(estimate=ggraph,p=p,q=q,parameter=parameter_bic2)
evaluation_bic2[iter,,j]<-c(Eva_count(B=B,P=P,Phi=Phi,Est=est,reverse=F), Eva_total(B=B,P=P,Phi=Phi,Est=est,reverse=F))
est<-combine(ggraph,p=p,q=q, cd='or', cc='or',dd='or')
evaluation_or[iter,,j]<-c(Eva_count(B=B,P=P,Phi=Phi,Est=est,reverse=F), Eva_total(B=B,P=P,Phi=Phi,Est=est,reverse=F))
est<-combine(ggraph,p=p,q=q, cd='and', cc='or',dd='or')
evaluation_and[iter,,j]<-c(Eva_count(B=B,P=P,Phi=Phi,Est=est,reverse=F), Eva_total(B=B,P=P,Phi=Phi,Est=est,reverse=F))
}
}
}
result<-edge_aver(edges=evaluation, count=count)
write.table(result, file=paste("./Estimates/G", iterg, "PB200_S.txt",sep=""))
result<-edge_aver(edges=evaluation_and, count=count)
write.table(result, file=paste("./Estimates/G", iterg, "PB200_AND.txt",sep=""))
result<-edge_aver(edges=evaluation_or, count=count)
write.table(result, file=paste("./Estimates/G", iterg, "PB200_OR.txt",sep=""))
result<-edge_aver(edges=evaluation_bic2, count=count)
write.table(result, file=paste("./Estimates/G", iterg, "PB200_BIC2.txt",sep=""))
print(count)
}
source("../Sources/MGM_misc.r")
count<-count+1
sds<-as.numeric(apply(sample_limited, 2, sd))
est_path<-neighbour_PB(dat=sample_limited,p=p,q=q,
clambda=lambda, ratio=1, pf=T, pw=sds,maxit=10000)
#preparation for applying the seleciton rules
source("../Sources/MGM_Evaluation.r")
source("../Sources/MGM_Combine.r")
source("../Sources/MGM_BIC.r")
source("../Sources/MGM_NSelect.r")
source("../Sources/MGM_misc.r")
est_path<-neighbour_PB(dat=sample_limited,p=p,q=q,
clambda=lambda, ratio=1, pf=T, pw=sds,maxit=10000)
source("../Sources/MGM_Evaluation.r")
source("../Sources/MGM_Combine.r")
source("../Sources/MGM_BIC.r")
source("../Sources/MGM_NSelect.r")
source("../Sources/MGM_misc.r")
est_path<-neighbour_PB(dat=sample_limited,p=p,q=q,
clambda=lambda, ratio=1, pf=T, pw=sds,maxit=10000)
source("../Sources/MGM_Evaluation.r")
source("../Sources/MGM_Combine.r")
source("../Sources/MGM_BIC.r")
source("../Sources/MGM_NSelect.r")
source("../Sources/MGM_misc.r")
est_path<-neighbour_PB(dat=sample_limited,p=p,q=q,
clambda=lambda, ratio=1, pf=T, pw=sds,maxit=10000)
parameter_bic2<-parameter<-list(coef=1, a0=1)
parameter$coef<- rbind(cbind(B,P), cbind(t(P),Phi))
parameter$a0 <- c(rep(meanlow,p/2),rep(meanhigh,p/2))
bytype<-BIC_type(bic=est_path$bic,p=p,q=q)
parameter_bic2$a0 <- est_path$Intercept[1:p,bytype[1]+gap]
parameter_bic2$coef<- rbind(est_path$N[1:p,,bytype[1]+gap],est_path$N[p+(1:q),,bytype[2]+7])
gr<-list(1,2,3)
meanlow<- -3
meanhigh <- 0
total<-100
lambda<-exp(-seq(from= 6, to= -4, length.out=total))
#calculate the number we need in order to get 1/2
gap<-ceiling(log(2)/ log(lambda[2]/lambda[1])) #~7
size<-200
M1<-3
M2<-3
#####
## Also need to pick the correct level of samples
for( iterg in 1:M1){
B<-as.matrix(read.csv(file=paste("./Graph/graphPB", "40 B",iterg, ".csv",sep=""),header=F))
P<-as.matrix(read.csv(file=paste("./Graph/graphPB", "40 P",iterg, ".csv",sep=""),header=F))
Phi<-as.matrix(read.csv(file=paste("./Graph/graphPB", "40 Phi",iterg, ".csv",sep=""),header=F))
p<-dim(P)[1]
q<-dim(P)[2]
count<-0
edges_BIC<-array(0,c(M2,8,3))
evaluation_bic2<-evaluation_or<-evaluation_and<-evaluation<-replicate(total,matrix(0,M2,8))
for(iter in 1:M2){
sample_all<-as.matrix(read.table(file=paste("./Data/sample40PB", iterg, "N400", iter,".txt",sep="" )))
sample_limited<-sample_all[1:size, ]
if(is_same(sample_limited)==TRUE){
} else {
count<-count+1
sds<-as.numeric(apply(sample_limited, 2, sd))
est_path<-neighbour_PB(dat=sample_limited,p=p,q=q,
clambda=lambda, ratio=1, pf=T, pw=sds,maxit=10000)
#preparation for applying the seleciton rules
parameter_bic2<-parameter<-list(coef=1, a0=1)
parameter$coef<- rbind(cbind(B,P), cbind(t(P),Phi))
parameter$a0 <- c(rep(meanlow,p/2),rep(meanhigh,p/2))
bytype<-BIC_type(bic=est_path$bic,p=p,q=q)
parameter_bic2$a0 <- est_path$Intercept[1:p,bytype[1]+gap]
parameter_bic2$coef<- rbind(est_path$N[1:p,,bytype[1]+gap],est_path$N[p+(1:q),,bytype[2]+7])
for(j in 1:total){
ggraph<-abs(est_path$N[,,j])
est<-combine_select(estimate=ggraph,p=p,q=q,parameter=parameter)
evaluation[iter,,j]<-c(Eva_count(B=B,P=P,Phi=Phi,Est=est,reverse=F), Eva_total(B=B,P=P,Phi=Phi,Est=est,reverse=F))
est<-combine_select(estimate=ggraph,p=p,q=q,parameter=parameter_bic2)
evaluation_bic2[iter,,j]<-c(Eva_count(B=B,P=P,Phi=Phi,Est=est,reverse=F), Eva_total(B=B,P=P,Phi=Phi,Est=est,reverse=F))
est<-combine(ggraph,p=p,q=q, cd='or', cc='or',dd='or')
evaluation_or[iter,,j]<-c(Eva_count(B=B,P=P,Phi=Phi,Est=est,reverse=F), Eva_total(B=B,P=P,Phi=Phi,Est=est,reverse=F))
est<-combine(ggraph,p=p,q=q, cd='and', cc='or',dd='or')
evaluation_and[iter,,j]<-c(Eva_count(B=B,P=P,Phi=Phi,Est=est,reverse=F), Eva_total(B=B,P=P,Phi=Phi,Est=est,reverse=F))
}
}
}
result<-edge_aver(edges=evaluation, count=count)
write.table(result, file=paste("./Estimates/G", iterg, "PB200_S.txt",sep=""))
result<-edge_aver(edges=evaluation_and, count=count)
write.table(result, file=paste("./Estimates/G", iterg, "PB200_AND.txt",sep=""))
result<-edge_aver(edges=evaluation_or, count=count)
write.table(result, file=paste("./Estimates/G", iterg, "PB200_OR.txt",sep=""))
result<-edge_aver(edges=evaluation_bic2, count=count)
write.table(result, file=paste("./Estimates/G", iterg, "PB200_BIC2.txt",sep=""))
print(count)
}
est<-combine_select(estimate=ggraph,p=p,q=q,parameter=parameter)
est<-combine_select(N=ggraph,p=p,q=q,parameter=parameter)
est<-combine_select(N=ggraph,p=p,q=q,parameter=parameter_bic2)
est<-combine(ggraph,p=p,q=q, cd='or', cc='or',dd='or')
est<-combine(ggraph,p=p,q=q, cd='and', cc='or',dd='or')
#####
## Also need to pick the correct level of samples
for( iterg in 1:M1){
B<-as.matrix(read.csv(file=paste("./Graph/graphPB", "40 B",iterg, ".csv",sep=""),header=F))
P<-as.matrix(read.csv(file=paste("./Graph/graphPB", "40 P",iterg, ".csv",sep=""),header=F))
Phi<-as.matrix(read.csv(file=paste("./Graph/graphPB", "40 Phi",iterg, ".csv",sep=""),header=F))
p<-dim(P)[1]
q<-dim(P)[2]
count<-0
edges_BIC<-array(0,c(M2,8,3))
evaluation_bic2<-evaluation_or<-evaluation_and<-evaluation<-replicate(total,matrix(0,M2,8))
for(iter in 1:M2){
sample_all<-as.matrix(read.table(file=paste("./Data/sample40PB", iterg, "N400", iter,".txt",sep="" )))
sample_limited<-sample_all[1:size, ]
if(is_same(sample_limited)==TRUE){
} else {
count<-count+1
sds<-as.numeric(apply(sample_limited, 2, sd))
est_path<-neighbour_PB(dat=sample_limited,p=p,q=q,
clambda=lambda, ratio=1, pf=T, pw=sds,maxit=10000)
#preparation for applying the seleciton rules
parameter_bic2<-parameter<-list(coef=1, a0=1)
parameter$coef<- rbind(cbind(B,P), cbind(t(P),Phi))
parameter$a0 <- c(rep(meanlow,p/2),rep(meanhigh,p/2))
bytype<-BIC_type(bic=est_path$bic,p=p,q=q)
parameter_bic2$a0 <- est_path$Intercept[1:p,bytype[1]+gap]
parameter_bic2$coef<- rbind(est_path$N[1:p,,bytype[1]+gap],est_path$N[p+(1:q),,bytype[2]+7])
for(j in 1:total){
ggraph<-abs(est_path$N[,,j])
est<-combine_select(N=ggraph,p=p,q=q,parameter=parameter)
evaluation[iter,,j]<-c(Eva_count(B=B,P=P,Phi=Phi,Est=est,reverse=F), Eva_total(B=B,P=P,Phi=Phi,Est=est,reverse=F))
est<-combine_select(N=ggraph,p=p,q=q,parameter=parameter_bic2)
evaluation_bic2[iter,,j]<-c(Eva_count(B=B,P=P,Phi=Phi,Est=est,reverse=F), Eva_total(B=B,P=P,Phi=Phi,Est=est,reverse=F))
est<-combine(ggraph,p=p,q=q, cd='or', cc='or',dd='or')
evaluation_or[iter,,j]<-c(Eva_count(B=B,P=P,Phi=Phi,Est=est,reverse=F), Eva_total(B=B,P=P,Phi=Phi,Est=est,reverse=F))
est<-combine(ggraph,p=p,q=q, cd='and', cc='or',dd='or')
evaluation_and[iter,,j]<-c(Eva_count(B=B,P=P,Phi=Phi,Est=est,reverse=F), Eva_total(B=B,P=P,Phi=Phi,Est=est,reverse=F))
}
}
}
result<-edge_aver(edges=evaluation, count=count)
write.table(result, file=paste("./Estimates/G", iterg, "PB200_S.txt",sep=""))
result<-edge_aver(edges=evaluation_and, count=count)
write.table(result, file=paste("./Estimates/G", iterg, "PB200_AND.txt",sep=""))
result<-edge_aver(edges=evaluation_or, count=count)
write.table(result, file=paste("./Estimates/G", iterg, "PB200_OR.txt",sep=""))
result<-edge_aver(edges=evaluation_bic2, count=count)
write.table(result, file=paste("./Estimates/G", iterg, "PB200_BIC2.txt",sep=""))
print(count)
}
source("../Sources/readplots.r")
M<-3
# Edge estimated using the interction (AND) rule
edge_and<-process(st1="./Estimates/G", st2="PB200_AND.txt",range=(1:M) )
# Edges estimated using the union (OR) rule
edge_or<-process(st1="./Estimates//G", st2="PB200_OR.txt",range=(1:M) )
# Edges estimated using the selection rule based on true parameters
edge_S<-process(st1="./Estimates/G", st2="PB200_S.txt",range=(1:M) )
# Edges estimated using the selection rule based on consistent estimators
edge_bic2<-process(st1="./Estimates/G", st2="PB200_BIC2.txt",range=(1:M) )
pdf(file = paste("./plots/PB-diff.pdf",sep=""), width=8, height=6)
par(mar=c(4,3.6,4,0.3)) # Margins
plot(edge_S[,2]~edge_S[,6],type="l",xlim=c(0,400),ylim=c(0,40), lwd=4,
xlab="Number of total estimated edges", ylab=" ",col="gray", cex.lab=2.2,cex.axis=1.5)
lines(edge_bic2[,2]~edge_bic2[,6],lwd=4,lty="dashed")
lines(edge_and[,2]~edge_and[,6],col="#FF4040",lwd=4,lty="solid")
lines(edge_or[,2]~edge_or[,6],col="#FF404090",lwd=4,lty="dashed")
mtext("Number of true edges", side=2, line=2.2,cex=2.2)
mtext('Edges between Poisson and binary nodes', outer=T, line=-2.8,cex=2.3)
dev.off()
source("../Sources/MGM_Graph.r")
source("./PB_Graph.r")
PB_Graph(M1=M1);
# Toy example
M1<-5 # Number of graphs
M2<-3 # Number of datasets for each graph
size<-200
PB_Select(M1=M1,M2=M2,size=size);
source("./PB_Select.r")
PB_Select(M1=M1,M2=M2,size=size);
## Required library
library(glmnet)
# Toy example
M1<-5 # Number of graphs
M2<-3 # Number of datasets for each graph
size<-200
source("../Sources/MGM_Graph.r")
source("./PB_Graph.r")
source("../Sources/MGM_Sampler.r")
source("./GB_Data.r")
source("../Sources/MGM_Sampler.r")
source("./PB_Data.r")
source("../Sources/MGM_Evaluation.r")
source("../Sources/MGM_Combine.r")
source("../Sources/MGM_BIC.r")
source("../Sources/MGM_NSelect.r")
source("../Sources/MGM_misc.r")
source("./PB_Select.r")
source("../Sources/MGM_misc.r")
edge_and<-process(st1="./Estimates/G", st2="PB200_AND.txt",range=(1:M) )
# Edges estimated using the union (OR) rule
edge_or<-process(st1="./Estimates//G", st2="PB200_OR.txt",range=(1:M) )
# Toy example
M1<-5 # Number of graphs
M2<-3 # Number of datasets for each graph
size<-200
edge_and<-process(st1="./Estimates/G", st2="PB200_AND.txt",range=(1:M1) )
edge_or<-process(st1="./Estimates//G", st2="PB200_OR.txt",range=(1:M1) )
edge_S<-process(st1="./Estimates/G", st2="PB200_S.txt",range=(1:M1) )
edge_bic2<-process(st1="./Estimates/G", st2="PB200_BIC2.txt",range=(1:M1) )
pdf(file = paste("./plots/PB-diff.pdf",sep=""), width=8, height=6)
par(mar=c(4,3.6,4,0.3)) # Margins
plot(edge_S[,2]~edge_S[,6],type="l",xlim=c(0,400),ylim=c(0,40), lwd=4,
xlab="Number of total estimated edges", ylab=" ",col="gray", cex.lab=2.2,cex.axis=1.5)
lines(edge_bic2[,2]~edge_bic2[,6],lwd=4,lty="dashed")
lines(edge_and[,2]~edge_and[,6],col="#FF4040",lwd=4,lty="solid")
lines(edge_or[,2]~edge_or[,6],col="#FF404090",lwd=4,lty="dashed")
mtext("Number of true edges", side=2, line=2.2,cex=2.2)
mtext('Edges between Poisson and binary nodes', outer=T, line=-2.8,cex=2.3)
dev.off()
source("./GB_Graph.r")
source("../Sources/MGM_Graph.r")
source("./probability_Graph.r")
