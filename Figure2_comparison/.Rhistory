B[i,i+1]<-B[i+1,i]<-1
}
B[B!=0]<-(2*rbinom(n=sum(B==1)/2,size=1, prob=0.5) -1)*runif(n=sum(B==1)/2,min=lwb, max=upb)
B[lower.tri(B)] <- t(B)[lower.tri(B)]
diag(B)<-1
if(min(eigen(B)$values)<0) {B<- B+diag(rep(1,p))*(0.1-min(eigen(B)$values))
B_norm<-1/sqrt(diag(p)*B)
B<-B_norm%*%B%*%B_norm
}
B
B<- B+diag(rep(1,p))*(0.1-min(eigen(B)$values))
B
B_norm<-1/sqrt(diag(p)*B)
B_norm
B_norm<-sqrt(diag(1/diag(B)))
B_norm
B<-B_norm%*%B%*%B_norm
B
source("../Sources/MGM_Graph.r")
gr<-generator(p=p, q=q, lwb=0.3, upb=0.6)
gr[[1]]
M1<-5
p<-q<-20
set.seed(12)
#####
for(i in 1:M1){
gr<-generator(p=p, q=q, lwb=0.3, upb=0.6)
write.table(gr[[1]],file=paste("./Graph/graphGB", "20 B", i,".csv",sep=""),row.names=F,col.names=F,sep=",")
write.table(gr[[2]],file=paste("./Graph/graphGB", "20 P", i,".csv",sep=""),row.names=F,col.names=F,sep=",")
write.table(gr[[3]],file=paste("./Graph/graphGB", "20 Phi", i,".csv",sep=""),row.names=F,col.names=F,sep=",")
}
M1<-5 # Number of graphs
M2<-3 # Number of datasets for each graph
for(iterg in 1:M1){
B<-as.matrix(read.csv(file=paste("./Graph/graphGB", "20 B",iterg, ".csv",sep=""),header=F))
P<-as.matrix(read.csv(file=paste("./Graph/graphGB", "20 P",iterg, ".csv",sep=""),header=F))
Phi<-as.matrix(read.csv(file=paste("./Graph/graphGB", "20 Phi",iterg, ".csv",sep=""),header=F))
p<-dim(P)[1]
q<-dim(P)[2]
for(iter in 1:M2){
set.seed(19+23*iter)
###For simulation in the paper: Gibbs.n=500, burnin=3000
rs<-sampler(400, B=B, P=P, Phi=Phi, seedmultiplier=(19+23*iter),
Gibbs.n=20,burnin=200)
write.table(rs,file=paste("./Data/sample20GB",iterg, "N400", iter, ".txt",sep=""))
}
}
source("../Sources/MGM_Evaluation.r")
source("../Sources/MGM_Combine.r")
source("../Sources/MGM_BIC.r")
source("../Sources/MGM_NSelect.r")
source("../Sources/MGM_misc.r")
total<-100
lambda<-exp(-seq(from= 4, to= -6, length.out=total))
size<-200
M1<-5
M2<-3
B<-as.matrix(read.csv(file=paste("./Graph/graphGB",  "20 B",iterg, ".csv",sep=""),header=F))
P<-as.matrix(read.csv(file=paste("./Graph/graphGB",  "20 P",iterg, ".csv",sep=""),header=F))
Phi<-as.matrix(read.csv(file=paste("./Graph/graphGB", "20 Phi",iterg, ".csv",sep=""),header=F))
p<-dim(P)[1]
q<-dim(P)[2]
count<-0
evaluation_ratio<-evaluation_node<-replicate(total,matrix(0,M2,8))
edges_BIC<-replicate(8,matrix(0,M2,3))
sample_all<-as.matrix(read.table(file=paste("./Data/sample20GB", iterg, "N400", iter,".txt",sep="" )))
sample_limited<-sample_all[1:size,]
count<-count+1
est_path<-neighbour.value(dat=sample_limited,p=p,q=q,
clambda=lambda, ratio=1, pf=T, pw=sds)
est_path<-neighbour(dat=sample_limited,p=p,q=q,
clambda=lambda, ratio=1, pf=T, pw=sds)
sds<-as.numeric(apply(sample_limited, 2, sd))
est_path<-neighbour(dat=sample_limited,p=p,q=q,
clambda=lambda, ratio=1, pf=T, pw=sds)
est_path<-neighbour(dat=sample_limited,p=p,q=q,
clambda=lambda, ratio=1, pf=T, pw=sds)
source("../Sources/MGM_NSelect.r")
est_path<-neighbour(dat=sample_limited,p=p,q=q,
clambda=lambda, ratio=1, pf=T, pw=sds)
source("../Sources/MGM_NSelect.r")
est_path<-neighbour(dat=sample_limited,p=p,q=q,
clambda=lambda, ratio=1, pf=T, pw=sds)
dat=sample_limited
clambda=lambda
ratio=1
pf=T
pw=sds
n<-dim(dat)[1]
#determine the tuning parameters for Gaussian nodes and binary nodes
lambda_g<-clambda*max(c(sqrt(2*log(p)/n),sqrt(2*log(q)/n)))
lambda_b<- ratio*lambda_g
nlambda_g<-length(lambda_g)
N<-replicate(nlambda_g, matrix(0,p+q,p+q))
A<-nlg<-bic<-matrix(0,p+q, nlambda_g)
i=1
penalty_weight=pw[-i]
scale_fac<-(p+q-1)/sum(penalty_weight)
penalty_weight<-scale_fac*penalty_weight
reg<-glmnet(x=scale_fac*dat[,-i], y=(dat[,i]), family="gaussian",
lambda=lambda_g, standardize=F,penalty.factor=penalty_weight )
as.matrix(reg$a0)
N[i,-i,]<-rbind(-(as.matrix(reg$beta))[1:(p-1),], (as.matrix(reg$beta))[p:(p+q-1),])*scale_fac
A[i,]<-as.matrix(reg$a0)
for(j in 1: nlambda_g ){
nlg[i,j]<-N2Loglklh(beta=as.matrix(reg$beta)[,j], a0=as.matrix(reg$a0)[j],
y=dat[,i], x=scale_fac*dat[,-i],dist='G')
bic[i,j]<-BIC(nlg[i,j],n,as.matrix(reg$beta)[,j])
}
list(N=N,Intercept=A,nlg=nlg,bic=bic)
lambda_g<-clambda*max(c(sqrt(2*log(p)/n),sqrt(2*log(q)/n)))
lambda_b<- ratio*lambda_g
nlambda_g<-length(lambda_g)
N<-replicate(nlambda_g, matrix(0,p+q,p+q))
A<-nlg<-bic<-matrix(0,p+q, nlambda_g)
for(i in 1:p){
#setting different weights for each coefficients, using pw.
if(pf==FALSE){
penalty_weight=rep(1,p+q-1)
} else{
penalty_weight=pw[-i]
}
# need to scale the covariate because glmnet will scale the tuning parameters
scale_fac<-(p+q-1)/sum(penalty_weight)
penalty_weight<-scale_fac*penalty_weight
reg<-glmnet(x=scale_fac*dat[,-i], y=(dat[,i]), family="gaussian",
lambda=lambda_g, standardize=F,penalty.factor=penalty_weight )
N[i,-i,]<-rbind(-(as.matrix(reg$beta))[1:(p-1),], (as.matrix(reg$beta))[p:(p+q-1),])*scale_fac
A[i,]<-as.matrix(reg$a0)
for(j in 1: nlambda_g ){
nlg[i,j]<-N2Loglklh(beta=as.matrix(reg$beta)[,j], a0=as.matrix(reg$a0)[j],
y=dat[,i], x=scale_fac*dat[,-i],dist='G')
bic[i,j]<-BIC(nlg[i,j],n,as.matrix(reg$beta)[,j])
}
}
for(i in p+(1:q)){
if(pf==FALSE){
penalty_weight=rep(1,p+q-1)
} else{
penalty_weight=pw[-i]
}
scale_fac<-(p+q-1)/sum(penalty_weight) #this is the scaling factor
penalty_weight<-scale_fac*penalty_weight
reg<-glmnet(x=scale_fac*dat[,-i], y=(dat[,i]>mean(dat[,i])), family="binomial",
lambda=lambda_b, standardize=F,penalty.factor=penalty_weight )
N[i,-i,]<- (as.matrix(reg$beta))*scale_fac
A[i,]<-as.matrix(reg$a0)
for(j in 1: nlambda_g ){
nlg[i,j]<-N2Loglklh(beta=as.matrix(reg$beta)[,j], a0=as.matrix(reg$a0)[j],
y=dat[,i], x=scale_fac*dat[,-i],dist='B')
bic[i,j]<-BIC(nlg[i,j],n,as.matrix(reg$beta)[,j])
}
}
i
reg<-glmnet(x=scale_fac*dat[,-i], y=(dat[,i]), family="gaussian",
lambda=lambda_g, standardize=F,penalty.factor=penalty_weight )
N[i,-i,]<-rbind(-(as.matrix(reg$beta))[1:(p-1),], (as.matrix(reg$beta))[p:(p+q-1),])*scale_fac
A[i,]<-as.matrix(reg$a0)
for(j in 1: nlambda_g ){
nlg[i,j]<-N2Loglklh(beta=as.matrix(reg$beta)[,j], a0=as.matrix(reg$a0)[j],
y=dat[,i], x=scale_fac*dat[,-i],dist='G')
bic[i,j]<-BIC(nlg[i,j],n,as.matrix(reg$beta)[,j])
}
scale_fac<-(p+q-1)/sum(penalty_weight) #this is the scaling factor
penalty_weight<-scale_fac*penalty_weight
reg<-glmnet(x=scale_fac*dat[,-i], y=(dat[,i]>mean(dat[,i])), family="binomial",
lambda=lambda_b, standardize=F,penalty.factor=penalty_weight )
reg<-glmnet(x=scale_fac*dat[,-i], y=(dat[,i]>mean(dat[,i])), family="binomial",
lambda=lambda_b, standardize=F,penalty.factor=penalty_weight )
scale_fac
sum(penalty_weight)
(p+q-1)
pw[-i]
penalty_weight=pw[-i]
scale_fac<-(p+q-1)/sum(penalty_weight) #this is the scaling factor
scale_fac
penalty_weight<-scale_fac*penalty_weight
reg<-glmnet(x=scale_fac*dat[,-i], y=(dat[,i]>mean(dat[,i])), family="binomial",
lambda=lambda_b, standardize=F,penalty.factor=penalty_weight )
is_same(sample_limited)
source("../Sources/MGM_Evaluation.r")
source("../Sources/MGM_Combine.r")
source("../Sources/MGM_BIC.r")
source("../Sources/MGM_NSelect.r")
source("../Sources/MGM_misc.r")
total<-100
lambda<-exp(-seq(from= 4, to= -6, length.out=total))
size<-200
M1<-5
M2<-3
for( iterg in 1:M1){
B<-as.matrix(read.csv(file=paste("./Graph/graphGB",  "20 B",iterg, ".csv",sep=""),header=F))
P<-as.matrix(read.csv(file=paste("./Graph/graphGB",  "20 P",iterg, ".csv",sep=""),header=F))
Phi<-as.matrix(read.csv(file=paste("./Graph/graphGB", "20 Phi",iterg, ".csv",sep=""),header=F))
p<-dim(P)[1]
q<-dim(P)[2]
count<-0
evaluation_ratio<-evaluation_node<-replicate(total,matrix(0,M2,8))
edges_BIC<-replicate(8,matrix(0,M2,3))
for(iter in 1:M2){
sample_all<-as.matrix(read.table(file=paste("./Data/sample20GB", iterg, "N400", iter,".txt",sep="" )))
sample_limited<-sample_all[1:size,]
if(is_same(sample_limited)==TRUE){
} else {
count<-count+1
sds<-as.numeric(apply(sample_limited, 2, sd))
est_path<-neighbour(dat=sample_limited,p=p,q=q,
clambda=lambda, ratio=1, pf=T, pw=sds)
edges_BIC[iter,,]<-BIC_eval(N=est_path$N,bic=est_path$bic,p=p,q=q, B=B, P=P, Phi=Phi)
lambdas<-BIC_type(est_path$bic, p = p, q=q)
ratio_bic<-lambda[lambdas[1]]/lambda[lambdas[2]]
est_ratio<-neighbour.value(dat=sample_limited,p=p,q=q,
clambda.g=lambda, ratio=ratio_bic, pf=T, pw=sds,cf=F)
for(j in 1: total){
ggraph<-est_ratio$N[,,j]
est<-combine_gen(ggraph,p=p,q=q,cd='node', cc='or',dd='or')
evaluation_ratio[iter,,j]<-c(Eva_count(B=B,P=P,Phi=Phi,Est=est,reverse=F), Eva_total(B=B,P=P,Phi=Phi,Est=est,reverse=F))
}
}
}
result<-edge_aver(edges=evaluation_ratio, count=count)
write.table(result, file=paste("./Estimates/MGM/G", iterg, "MGM_ratio.txt",sep=""))
temp<-BIC_aver(edges=edges_BIC, B=B, P=P, Phi=Phi,count=count, type='number')
write.table(temp, file=paste("./Estimates/BIC/G", iterg, "BICcount200.txt",sep=""))
temp<-BIC_aver(edges=edges_BIC, B=B, P=P, Phi=Phi,count=count, type='rate')
write.table(temp, file=paste("./Estimates/BIC/G", iterg, "BICrate200.txt",sep=""))
}
total<-100
lambda<-exp(-seq(from= 4, to= -6, length.out=total))
size<-200
M1<-5
M2<-3
for( iterg in 1:M1){
B<-as.matrix(read.csv(file=paste("./Graph/graphGB",  "20 B",iterg, ".csv",sep=""),header=F))
P<-as.matrix(read.csv(file=paste("./Graph/graphGB",  "20 P",iterg, ".csv",sep=""),header=F))
Phi<-as.matrix(read.csv(file=paste("./Graph/graphGB", "20 Phi",iterg, ".csv",sep=""),header=F))
p<-dim(P)[1]
q<-dim(P)[2]
count<-0
evaluation_ratio<-evaluation_node<-replicate(total,matrix(0,M2,8))
edges_BIC<-replicate(8,matrix(0,M2,3))
for(iter in 1:M2){
sample_all<-as.matrix(read.table(file=paste("./Data/sample20GB", iterg, "N400", iter,".txt",sep="" )))
sample_limited<-sample_all[1:size,]
if(is_same(sample_limited)==TRUE){
} else {
count<-count+1
sds<-as.numeric(apply(sample_limited, 2, sd))
est_path<-neighbour(dat=sample_limited,p=p,q=q,
clambda=lambda, ratio=1, pf=T, pw=sds)
edges_BIC[iter,,]<-BIC_eval(N=est_path$N,bic=est_path$bic,p=p,q=q, B=B, P=P, Phi=Phi)
lambdas<-BIC_type(est_path$bic, p = p, q=q)
ratio_bic<-lambda[lambdas[1]]/lambda[lambdas[2]]
est_ratio<-neighbour(dat=sample_limited,p=p,q=q,
clambda=lambda, ratio=ratio_bic, pf=T, pw=sds)
for(j in 1: total){
ggraph<-est_ratio$N[,,j]
est<-combine(ggraph,p=p,q=q,cd='node', cc='or',dd='or')
evaluation_ratio[iter,,j]<-c(Eva_count(B=B,P=P,Phi=Phi,Est=est,reverse=F), Eva_total(B=B,P=P,Phi=Phi,Est=est,reverse=F))
}
}
}
result<-edge_aver(edges=evaluation_ratio, count=count)
write.table(result, file=paste("./Estimates/MGM/G", iterg, "MGM_ratio.txt",sep=""))
temp<-BIC_aver(edges=edges_BIC, B=B, P=P, Phi=Phi,count=count, type='number')
write.table(temp, file=paste("./Estimates/BIC/G", iterg, "BICcount200.txt",sep=""))
temp<-BIC_aver(edges=edges_BIC, B=B, P=P, Phi=Phi,count=count, type='rate')
write.table(temp, file=paste("./Estimates/BIC/G", iterg, "BICrate200.txt",sep=""))
}
source("../Sources/MGM_misc.r")
M1<-5
edgeMGM_ratio<-process(st1="./Estimates/MGM/G", st2="MGM_ratio.txt",range=(1:M1) )
BIC_count<-process(st1="./Estimates/BIC/G", st2="BICcount200.txt",range=(1:M1) )
BIC_rate<-process(st1="./Estimates/BIC/G", st2="BICrate200.txt",range=(1:M1) )
#Precision and recall rates
BIC_rate
plot(edgeMGM_ratio[,2]~edgeMGM_ratio[,6],type="l",xlim=c(0,150),ylim=c(0,22), lwd=4,
xlab="Number of total estimated edges", yaxt='n', ylab='', cex.lab=2.2,cex.axis=1.5)
points(BIC_count[2,2]~BIC_count[2,6],pch=c(17),cex=2)
plot(edgeMGMR_same[1,]~edgeMGMR_same[2,],type="l",xlim=c(0,240),ylim=c(0,38),
xlab="Number of total estimated edges", col="black", lwd=4, yaxt='n', ylab='', cex.lab=2.2,cex.axis=1.5)
edgeMGMR_same<-rbind(apply(edgeMGM_ratio[,c(1,4)],1,sum), apply(edgeMGM_ratio[,c(5,8)],1,sum))
edgeMB_same<-rbind(apply(edgeMB_or[,c(1,4)],1,sum), apply(edgeMB_or[,c(5,8)],1,sum))
edgeGR_same<-rbind(apply(edgeGR[,c(1,4)],1,sum), apply(edgeGR[,c(5,8)],1,sum))
edgeI_same<-rbind(apply(edgeI_or[,c(1,4)],1,sum), apply(edgeI_or[,c(5,8)],1,sum))
BIC_same<-rbind(apply(BIC_count[,c(1,4)],1,sum), apply(BIC_count[,c(5,8)],1,sum))
plot(edgeMGMR_same[1,]~edgeMGMR_same[2,],type="l",xlim=c(0,240),ylim=c(0,38),
xlab="Number of total estimated edges", col="black", lwd=4, yaxt='n', ylab='', cex.lab=2.2,cex.axis=1.5)
points(BIC_same[1,2]~BIC_same[2,2],pch=c(17),cex=2)
source("../Sources/MGM_Evaluation.r")
source("../Sources/MGM_Combine.r")
source("../Sources/MGM_BIC.r")
source("../Sources/MGM_NSelect.r")
source("../Sources/MGM_misc.r")
# Required library
library(glasso)
p<-20
q<-20
total<-100
lambda<-exp(-seq(from= 4, to= -6, length.out=total))
size<-200
rho.vec<-sqrt(2*log(p)/size)*lambda/2
p<-20
q<-20
total<-100
lambda<-exp(-seq(from= 4, to= -6, length.out=total))
size<-200
rho.vec<-sqrt(2*log(p)/size)*lambda/2
M1<-5
M2<-3
for( iterg in 1:M1){
B<-as.matrix(read.csv(file=paste("./Graph/graphGB",  "20 B",iterg, ".csv",sep=""),header=F))
P<-as.matrix(read.csv(file=paste("./Graph/graphGB",  "20 P",iterg, ".csv",sep=""),header=F))
Phi<-as.matrix(read.csv(file=paste("./Graph/graphGB", "20 Phi",iterg, ".csv",sep=""),header=F))
count<-0
evaluation_or<-replicate(total,matrix(0,M2,8))
for(iter in 1:M2){
sample_all<-as.matrix(read.table(file=paste("./Data/sample20GB", iterg, "N400", iter,".txt",sep="" )))
sample_limited<-sample_all[1:size,]
if(is_same(sample_limited)==TRUE){
} else {
count<-count+1
sample_limited<-sample_limited-rep(1,size)%*%t(apply(sample_limited,2,mean))
sample_limited<-sign(sample_limited)
sds<-as.numeric(apply(sample_limited, 2, sd))
est_path<-Ising(dat=sample_limited,p=p,q=q, clambda.g=lambda, pf=T, pw=sds)
for(j in 1: total){
ggraph<-est_path[,,j]
est<-combine(ggraph,p=p,q=q, cd='or', cc='or',dd='or')
evaluation_or[iter,,j]<-c(Eva_count(B=B,P=P,Phi=Phi,Est=est,reverse=F), Eva_total(B=B,P=P,Phi=Phi,Est=est,reverse=F))
}
}
}
result<-edge_aver(edges=evaluation_or, count=count)
write.table(result, file=paste("./Estimates/Ising/G", iterg, "I_or.txt",sep=""))
}
est_path<-neighbour_Ising(dat=sample_limited,p=p,q=q, clambda.g=lambda, pf=T, pw=sds)
est_path<-neighbour_Ising(dat=sample_limited,p=p,q=q, clambda=lambda, pf=T, pw=sds)
source("../Sources/MGM_NSelect.r")
est_path<-neighbour_Ising(dat=sample_limited,p=p,q=q, clambda=lambda, pf=T, pw=sds)
p<-20
q<-20
total<-100
lambda<-exp(-seq(from= 4, to= -6, length.out=total))
size<-200
rho.vec<-sqrt(2*log(p)/size)*lambda/2
M1<-5
M2<-3
for( iterg in 1:M1){
B<-as.matrix(read.csv(file=paste("./Graph/graphGB",  "20 B",iterg, ".csv",sep=""),header=F))
P<-as.matrix(read.csv(file=paste("./Graph/graphGB",  "20 P",iterg, ".csv",sep=""),header=F))
Phi<-as.matrix(read.csv(file=paste("./Graph/graphGB", "20 Phi",iterg, ".csv",sep=""),header=F))
count<-0
evaluation_or<-replicate(total,matrix(0,M2,8))
for(iter in 1:M2){
sample_all<-as.matrix(read.table(file=paste("./Data/sample20GB", iterg, "N400", iter,".txt",sep="" )))
sample_limited<-sample_all[1:size,]
if(is_same(sample_limited)==TRUE){
} else {
count<-count+1
sample_limited<-sample_limited-rep(1,size)%*%t(apply(sample_limited,2,mean))
sample_limited<-sign(sample_limited)
sds<-as.numeric(apply(sample_limited, 2, sd))
est_path<-neighbour_Ising(dat=sample_limited,p=p,q=q, clambda=lambda, pf=T, pw=sds)
for(j in 1: total){
ggraph<-est_path[,,j]
est<-combine(ggraph,p=p,q=q, cd='or', cc='or',dd='or')
evaluation_or[iter,,j]<-c(Eva_count(B=B,P=P,Phi=Phi,Est=est,reverse=F), Eva_total(B=B,P=P,Phi=Phi,Est=est,reverse=F))
}
}
}
result<-edge_aver(edges=evaluation_or, count=count)
write.table(result, file=paste("./Estimates/Ising/G", iterg, "I_or.txt",sep=""))
}
# ####################
# #  M & B 2006      #
# ####################
for( iterg in 1:M1){
B<-as.matrix(read.csv(file=paste("./Graph/graphGB",  "20 B",iterg, ".csv",sep=""),header=F))
P<-as.matrix(read.csv(file=paste("./Graph/graphGB",  "20 P",iterg, ".csv",sep=""),header=F))
Phi<-as.matrix(read.csv(file=paste("./Graph/graphGB", "20 Phi",iterg, ".csv",sep=""),header=F))
count<-0
evaluation_or<-replicate(total,matrix(0,M2,8))
for(iter in 1:M2){
sample_all<-as.matrix(read.table(file=paste("./Data/sample20GB", iterg, "N400", iter,".txt",sep="" )))
sample_limited<-sample_all[1:size,]
if(is_same(sample_limited)==TRUE){
} else {
count<-count+1
sds<-as.numeric(apply(sample_limited, 2, sd))
est_path<-neighbour_Gaussian(dat=sample_limited,p=p,q=q,
clambda=lambda, pf=T, pw=sds)
for(j in 1: total){
ggraph<-est_path[,,j]
est<-combine(ggraph,p=p,q=q, cd='or', cc='or',dd='or')
evaluation_or[iter,,j]<-c(Eva_count(B=B,P=P,Phi=Phi,Est=est,reverse=F), Eva_total(B=B,P=P,Phi=Phi,Est=est,reverse=F))
}
}
}
result<-edge_aver(edges=evaluation_or, count=count)
write.table(result, file=paste("./Estimates/MB/G", iterg, "MB_or.txt",sep=""))
}
source("../Sources/MGM_NSelect.r")
# ####################
# #  M & B 2006      #
# ####################
for( iterg in 1:M1){
B<-as.matrix(read.csv(file=paste("./Graph/graphGB",  "20 B",iterg, ".csv",sep=""),header=F))
P<-as.matrix(read.csv(file=paste("./Graph/graphGB",  "20 P",iterg, ".csv",sep=""),header=F))
Phi<-as.matrix(read.csv(file=paste("./Graph/graphGB", "20 Phi",iterg, ".csv",sep=""),header=F))
count<-0
evaluation_or<-replicate(total,matrix(0,M2,8))
for(iter in 1:M2){
sample_all<-as.matrix(read.table(file=paste("./Data/sample20GB", iterg, "N400", iter,".txt",sep="" )))
sample_limited<-sample_all[1:size,]
if(is_same(sample_limited)==TRUE){
} else {
count<-count+1
sds<-as.numeric(apply(sample_limited, 2, sd))
est_path<-neighbour_Gaussian(dat=sample_limited,p=p,q=q,
clambda=lambda, pf=T, pw=sds)
for(j in 1: total){
ggraph<-est_path[,,j]
est<-combine(ggraph,p=p,q=q, cd='or', cc='or',dd='or')
evaluation_or[iter,,j]<-c(Eva_count(B=B,P=P,Phi=Phi,Est=est,reverse=F), Eva_total(B=B,P=P,Phi=Phi,Est=est,reverse=F))
}
}
}
result<-edge_aver(edges=evaluation_or, count=count)
write.table(result, file=paste("./Estimates/MB/G", iterg, "MB_or.txt",sep=""))
}
####################
for( iterg in 1:M1){
B<-as.matrix(read.csv(file=paste("./Graph/graphGB",  "20 B",iterg, ".csv",sep=""),header=F))
P<-as.matrix(read.csv(file=paste("./Graph/graphGB",  "20 P",iterg, ".csv",sep=""),header=F))
Phi<-as.matrix(read.csv(file=paste("./Graph/graphGB", "20 Phi",iterg, ".csv",sep=""),header=F))
count<-0
evaluation<-replicate(total,matrix(0,M2,8))
for(iter in 1:M2){
sample_all<-as.matrix(read.table(file=paste("./Data/sample20GB", iterg, "N400", iter,".txt",sep="" )))
sample_limited<-sample_all[1:size,]
if(is_same(sample_limited)==TRUE){
} else {
count<-count+1
est_path<-glassopath(s=cor(sample_limited)*(size-1)/size, rholist=rho.vec, approx=F, penalize.diagonal=F,thr=1e-07)
for(j in 1: total){
ggraph<-abs(est_path$wi[,,j])
est<-combine(ggraph,p=p,q=q,cd='node', cc='or',dd='or')
evaluation[iter,,j]<-c(Eva_count(B=B,P=P,Phi=Phi,Est=est,reverse=F), Eva_total(B=B,P=P,Phi=Phi,Est=est,reverse=F))
}
}
}
result<-edge_aver(edges=evaluation, count=count)
write.table(result, file=paste("./Estimates/Glasso/G", iterg, "GR.txt",sep=""))
}
M1<-5
edgeMGM_ratio<-process(st1="./Estimates/MGM/G", st2="MGM_ratio.txt",range=(1:M1) )
edgeGR<-process(st1="./Estimates/Glasso/G", st2="GR.txt",range=(1:M1) )
edgeMB_or<-process(st1="./Estimates/MB/G", st2="MB_or.txt",range=(1:M1) )
edgeI_or<-process(st1="./Estimates/Ising/G", st2="I_or.txt",range=(1:M1) )
BIC_count<-process(st1="./Estimates/BIC/G", st2="BICcount200.txt",range=(1:M1) )
BIC_rate<-process(st1="./Estimates/BIC/G", st2="BICrate200.txt",range=(1:M1) )
#Precision and recall rates
BIC_rate
plot(edgeMGM_ratio[,2]~edgeMGM_ratio[,6],type="l",xlim=c(0,150),ylim=c(0,22), lwd=4,
xlab="Number of total estimated edges", yaxt='n', ylab='', cex.lab=2.2,cex.axis=1.5)
lines(edgeMB_or[,2]~edgeMB_or[,6],col="#FF4040", lty="longdash", lwd=4)
lines(edgeGR[,2]~edgeGR[,6],col="#FF404090", lty="dashed",lwd=4)
lines(edgeI_or[,2]~edgeI_or[,6],col="#FF404070",  lwd=4)
points(BIC_count[2,2]~BIC_count[2,6],pch=c(17),cex=2)
edgeMGMR_same<-rbind(apply(edgeMGM_ratio[,c(1,4)],1,sum), apply(edgeMGM_ratio[,c(5,8)],1,sum))
edgeMB_same<-rbind(apply(edgeMB_or[,c(1,4)],1,sum), apply(edgeMB_or[,c(5,8)],1,sum))
edgeGR_same<-rbind(apply(edgeGR[,c(1,4)],1,sum), apply(edgeGR[,c(5,8)],1,sum))
edgeI_same<-rbind(apply(edgeI_or[,c(1,4)],1,sum), apply(edgeI_or[,c(5,8)],1,sum))
BIC_same<-rbind(apply(BIC_count[,c(1,4)],1,sum), apply(BIC_count[,c(5,8)],1,sum))
plot(edgeMGMR_same[1,]~edgeMGMR_same[2,],type="l",xlim=c(0,240),ylim=c(0,38),
xlab="Number of total estimated edges", col="black", lwd=4, yaxt='n', ylab='', cex.lab=2.2,cex.axis=1.5)
lines(edgeMB_same[1,]~edgeMB_same[2,], col="#FF4040",lty="longdash", lwd=4)
lines(edgeGR_same[1,]~edgeGR_same[2,],col="#FF404090", lty="dashed", lwd=4)
lines(edgeI_same[1,]~edgeI_same[2,],col="#FF404070", lwd=4)
points(BIC_same[1,2]~BIC_same[2,2],pch=c(17),cex=2)
pdf(file = paste("./plots/GB-diff.pdf",sep=""), width=8, height=6)
par(mfrow=c(1,1))
par(mar=c(4,3.6,4,0.3)) # Margins
plot(edgeMGM_ratio[,2]~edgeMGM_ratio[,6],type="l",xlim=c(0,150),ylim=c(0,22), lwd=4,
xlab="Number of total estimated edges", yaxt='n', ylab='', cex.lab=2.2,cex.axis=1.5)
lines(edgeMB_or[,2]~edgeMB_or[,6],col="#FF4040", lty="longdash", lwd=4)
lines(edgeGR[,2]~edgeGR[,6],col="#FF404090", lty="dashed",lwd=4)
lines(edgeI_or[,2]~edgeI_or[,6],col="#FF404070",  lwd=4)
points(BIC_count[2,2]~BIC_count[2,6],pch=c(17),cex=2)
axis(2,cex.axis=1.5)
mtext("Number of true edges", side=2, line=2.2,cex=2.2)
mtext('Edges between Gaussian and binary nodes', outer=T, line=-2.8,cex=2.3)
dev.off()
## plot of edges of the same type
edgeMGMR_same<-rbind(apply(edgeMGM_ratio[,c(1,4)],1,sum), apply(edgeMGM_ratio[,c(5,8)],1,sum))
edgeMB_same<-rbind(apply(edgeMB_or[,c(1,4)],1,sum), apply(edgeMB_or[,c(5,8)],1,sum))
edgeGR_same<-rbind(apply(edgeGR[,c(1,4)],1,sum), apply(edgeGR[,c(5,8)],1,sum))
edgeI_same<-rbind(apply(edgeI_or[,c(1,4)],1,sum), apply(edgeI_or[,c(5,8)],1,sum))
BIC_same<-rbind(apply(BIC_count[,c(1,4)],1,sum), apply(BIC_count[,c(5,8)],1,sum))
pdf(file = paste("./plots/GB-same.pdf",sep=""), width=8, height=6)
par(mar=c(4,3.6,4,0.3)) # Margins
plot(edgeMGMR_same[1,]~edgeMGMR_same[2,],type="l",xlim=c(0,240),ylim=c(0,38),
xlab="Number of total estimated edges", col="black", lwd=4, yaxt='n', ylab='', cex.lab=2.2,cex.axis=1.5)
lines(edgeMB_same[1,]~edgeMB_same[2,], col="#FF4040",lty="longdash", lwd=4)
lines(edgeGR_same[1,]~edgeGR_same[2,],col="#FF404090", lty="dashed", lwd=4)
lines(edgeI_same[1,]~edgeI_same[2,],col="#FF404070", lwd=4)
points(BIC_same[1,2]~BIC_same[2,2],pch=c(17),cex=2)
axis(2,cex.axis=1.5)
mtext("Number of true edges", side=2, line=2.2,cex=2.2)
mtext('Edges between same types of nodes', outer=T, line=-2.8,cex=2.3)
dev.off()
